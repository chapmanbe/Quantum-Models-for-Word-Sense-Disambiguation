{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Disambiguatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy import Ty, Word\n",
    "from words import sub_nouns as nouns\n",
    "from words import sub_sentences as sentences\n",
    "\n",
    "s, n = Ty('s'), Ty('n')\n",
    "\n",
    "dataset = []\n",
    "nouns, verbs = set(), set()\n",
    "for sentence in sentences:\n",
    "    _s = sentence.split(\" \")\n",
    "    dataset.append([_s[0],_s[1],int(_s[2][1])])\n",
    "    verbs.add(_s[0])\n",
    "    nouns.add(_s[1])\n",
    "\n",
    "\n",
    "ambiguous_verbs = [\"file\"] #, \"dribble\", \"tap\", \"charge\"]\n",
    "\n",
    "\n",
    "# nouns\n",
    "noun_voc = {noun: Word(noun, n) for noun in nouns}\n",
    "unamb_verb_voc = {verb: Word(verb, s @ n.l) for verb in verbs if verb not in ambiguous_verbs}\n",
    "amb_verb_voc = {amb: Word(amb, s @ n.l) for amb in ambiguous_verbs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unamb_verb_voc)\n",
    "print(amb_verb_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and parse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from discopy import Diagram, Id, Cup\n",
    "from discopy.grammar import brute_force\n",
    "\n",
    "grammar = Id(s) @ Cup(n.l, n)\n",
    "sentences, plausability, parsing = list(), list(), dict()\n",
    "\n",
    "start = time()\n",
    "for entry in dataset:\n",
    "    sentence = ' '.join(entry[0:2]) + '.'\n",
    "    sentences.append(sentence)\n",
    "    plausability.append(entry[2])\n",
    "\n",
    "    verb = unamb_verb_voc.get(entry[0], False)\n",
    "    if not verb:\n",
    "        verb = amb_verb_voc[entry[0]]\n",
    "    obj = noun_voc[entry[1]]\n",
    "    diagram = verb @ obj >> grammar\n",
    "\n",
    "    parsing.update({sentence: diagram})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a random sentence\n",
    "i = 10\n",
    "print(sentences[i],\" plausability: \", plausability[i])\n",
    "parsing[sentences[i]].draw(draw_type_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Ket, H, Rx, Ry, Rz, CX, sqrt, X, Circuit\n",
    "from random import uniform\n",
    "from math import pi\n",
    "\n",
    "\n",
    "# AnsÃ¤tze for 1-qubit states\n",
    "def un_amb_verb_ansatz(p):\n",
    "    return Ket(p[0])\n",
    "\n",
    "def amb_verb_ansatz(p):\n",
    "    return Ket(0) >>  \\\n",
    "        Rx(p[0])\n",
    "\n",
    "def noun_ansatz(p):\n",
    "    return Ket(0) >> \\\n",
    "        Rx(p[0]) >> \\\n",
    "        Rz(p[1])\n",
    "\n",
    "\n",
    "n_qubits_ansatz = 1\n",
    "n_noun_params = 2\n",
    "n_amb_params = 1\n",
    "\n",
    "print(amb_verb_ansatz([uniform(0,1) for i in range(n_amb_params)]).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare intitial params\n",
    "binaries = [list(bin(i)[2:]) for i, verb in enumerate(unamb_verb_voc.keys())]\n",
    "int_binaries = [[0]*(n_qubits_ansatz - len(bi)) + [int(b) for b in bi] for bi in binaries]\n",
    "\n",
    "n_nouns = len(nouns)\n",
    "n_amb_verbs = len(ambiguous_verbs)\n",
    "n_unamb_verbs = len(unamb_verb_voc)\n",
    "\n",
    "params_unamb_verbs = {verb: int_binaries[i] for i, verb in enumerate(unamb_verb_voc.keys())}\n",
    "params_nouns = {noun: [uniform(0, 1) for i in range(n_noun_params)] for noun in noun_voc}\n",
    "params_amb_verbs = {verb: [uniform(0, 1) for i in range(n_amb_params)] for verb in amb_verb_voc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_unamb_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy import CircuitFunctor, qubit\n",
    "\n",
    "\n",
    "def F(params_nouns, params_unamb_verbs, params_amb_verbs):\n",
    "    ar1 = {noun_voc[noun]:noun_ansatz(params_nouns[noun]) for noun in noun_voc}\n",
    "    ar2 = {unamb_verb_voc[verb]:un_amb_verb_ansatz(params_unamb_verbs[verb]) for verb in unamb_verb_voc}\n",
    "    ar3 = {amb_verb_voc[verb]:amb_verb_ansatz(params_amb_verbs[verb]) for verb in amb_verb_voc}\n",
    "    ar = {**ar1, **ar2, **ar3}\n",
    "\n",
    "    return CircuitFunctor(\n",
    "        ob = {s: qubit ** 0, n: qubit ** n_qubits_ansatz},\n",
    "        ar = ar)\n",
    "\n",
    "print(\"Circuit for 'register account.':\")\n",
    "circuit = F(params_nouns, params_unamb_verbs, params_amb_verbs)(parsing['register account.'])\n",
    "circuit.draw(figsize=(6, 6), aspect='auto', draw_type_labels=False)\n",
    "circuit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend, tk_to_qiskit\n",
    "backend = AerBackend()\n",
    "result = circuit.eval(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_circ = circuit.to_tk()\n",
    "print(\"{}:\\n{}\\n\".format(tk_circ, '\\n'.join(map(str, tk_circ))))\n",
    "print(\"post selection:\\n{}\\n\".format(tk_circ.post_selection))\n",
    "print(\"scalar:\\n{}\\n\".format(tk_circ.scalar))\n",
    "print(\"qiskit circuit:\")\n",
    "tk_to_qiskit(tk_circ).draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define evaluation function\n",
    "def evaluate(params_nouns, params_unamb_verbs, params_amb_verbs, sentences, backend=AerBackend(), n_shots=2**10, seed=0):\n",
    "    circuits = [F(params_nouns, params_unamb_verbs, params_amb_verbs)(parsing[sent]) for sent in sentences]\n",
    "    results = [Circuit.eval(\n",
    "                circuit,\n",
    "                backend=backend,\n",
    "                n_shots=n_shots,\n",
    "                seed=seed,\n",
    "                compilation=backend.default_compilation_pass(2)) for circuit in circuits]\n",
    "    tensors = [np.abs(result.array)[0] for result in results]\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(params_np):\n",
    "    ''' Converts numpy array of parameters back to dictionary\n",
    "    '''\n",
    "    params_nouns_np = params_np[:n_nouns*n_noun_params].reshape((n_nouns,n_noun_params))\n",
    "    params_amb_verbs_np = params_np[n_nouns*n_noun_params:].reshape((n_amb_verbs,n_amb_params))\n",
    "\n",
    "    params_nouns = {word: params_nouns_np[i].tolist() for i, word in enumerate(nouns)}\n",
    "    params_amb_verbs = {word: params_amb_verbs_np[i].tolist() for i, word in enumerate(amb_verb_voc)}\n",
    "\n",
    "    return params_nouns, params_amb_verbs\n",
    "\n",
    "def loss(params_np, sentences=sentences, plausability=plausability):\n",
    "\n",
    "    # convert np to dict\n",
    "    params_nouns, params_amb_verbs = reshape_data(params_np)\n",
    "\n",
    "    return np.mean(np.array([\n",
    "        (plausability[i] - scalar) ** 2\n",
    "        for i, scalar in enumerate(evaluate(params_nouns, params_unamb_verbs, params_amb_verbs, sentences))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model with genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "algorithm_param = {\n",
    "    'max_num_iteration': 25,\\\n",
    "    'population_size':5,\\\n",
    "    'mutation_probability':0.1,\\\n",
    "    'elit_ratio': 0.01,\\\n",
    "    'crossover_probability': 0.5,\\\n",
    "    'parents_portion': 0.3,\\\n",
    "    'crossover_type':'uniform',\\\n",
    "    'max_iteration_without_improv':None\n",
    "}\n",
    "\n",
    "dimension = n_noun_params*n_nouns + n_amb_params*n_amb_verbs\n",
    "varbound=np.array([[0,1]]*dimension)\n",
    "\n",
    "model=ga(function=loss,dimension=dimension, variable_type='real',variable_boundaries=varbound, algorithm_parameters=algorithm_param, function_timeout=100)\n",
    "\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results after GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_nouns, best_params_amb_verbs = reshape_data(model.best_variable)\n",
    "print(best_params_nouns)\n",
    "print(\"\\n\")\n",
    "print(best_params_amb_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wave function of \"file\"\n",
    "print(amb_verb_ansatz(best_params_amb_verbs['file']).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss2(params_np, sentences=sentences, plausability=plausability):\n",
    "\n",
    "    # convert back to dict\n",
    "    params_nouns, params_amb_verbs = reshape_data(params_np)\n",
    "\n",
    "    return  {sentences[i]:(plausability[i], round(scalar,4))\n",
    "        for i, scalar in enumerate(evaluate(params_nouns, params_unamb_verbs, params_amb_verbs, sentences))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output computed values vs. true values\n",
    "loss2(model.best_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune with noisyopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import noisyopt\n",
    "from time import time\n",
    "i, start = 0, time()\n",
    "\n",
    "def callback(loss):\n",
    "    global i\n",
    "    i += 1\n",
    "    print(\"Epoch {} ({:.0f} seconds since start): {}\".format(i, time() - start, loss))\n",
    "\n",
    "result = noisyopt.minimizeSPSA(\n",
    "    loss, model.best_variable, paired=False, callback=callback, niter=200, a=0.2, c=0.1)\n",
    "\n",
    "print(\"Best loss: \", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = loss2(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = result.fun\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "folder = './experiments/1_qb_model_' + datetime.datetime.now().strftime(\"%Y-%m-%d\")+ \"_best_loss_\" + str(round(best_loss,4))\n",
    "os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "params_nouns, params_amb_verbs = reshape_data(result.x)\n",
    "\n",
    "fiel_path_params_amb_verbs = os.path.join(folder,'parameters_amb_verbs.json')\n",
    "fiel_path_params_unamb_verbs = os.path.join(folder,'parameters_unamb_verbs.json')\n",
    "fiel_path_params_nouns = os.path.join(folder,'params_nouns.json')\n",
    "\n",
    "fiel_path_results = os.path.join(folder,'results.json')\n",
    "\n",
    "with open(fiel_path_params_amb_verbs, 'w') as fp:\n",
    "    json.dump(params_amb_verbs, fp)\n",
    "\n",
    "with open(fiel_path_params_unamb_verbs, 'w') as fp:\n",
    "    json.dump(params_unamb_verbs, fp)\n",
    "\n",
    "with open(fiel_path_params_nouns, 'w') as fp:\n",
    "    json.dump(params_nouns, fp)\n",
    "\n",
    "with open(fiel_path_results, 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimizer evolution steps for animation\n",
    "evolution_genetic = dict()\n",
    "# deleted _report; see if thsi works\n",
    "for i, sol in enumerate(model.best_variable_report):\n",
    "    key = \"evo\" + str(i+1)\n",
    "    params_nouns_ev, params_amb_verbs_ev = reshape_data(sol)\n",
    "    evolution_genetic[key] = {\"nouns\": params_nouns_ev, \"amb_verbs\": params_amb_verbs_ev}\n",
    "\n",
    "\n",
    "file_path_evolution = os.path.join(folder,'params_evolution_genetic.json')\n",
    "with open(file_path_evolution, 'w') as fp:\n",
    "    json.dump(evolution_genetic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimizer evolution steps for animation\n",
    "evolution_noisy = dict()\n",
    "for sol in result.evo:\n",
    "    params_nouns_ev, params_amb_verbs_ev = reshape_data(result.evo[sol])\n",
    "    evolution_noisy[sol] = {\"nouns\": params_nouns_ev, \"amb_verbs\": params_amb_verbs_ev}\n",
    "\n",
    "evolution_noisy[\"loss\"] = result.loss_arr\n",
    "\n",
    "fiel_path_evolution = os.path.join(folder,'params_evolution_noisy.json')\n",
    "with open(fiel_path_evolution, 'w') as fp:\n",
    "    json.dump(evolution_noisy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qnlp-ws)",
   "language": "python",
   "name": "qnlp-ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "597cb9212bb6505db551d0fa5a39e44e38662ecd79044286d7f1c9c46fe55c66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
