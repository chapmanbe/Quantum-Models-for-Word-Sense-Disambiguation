{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for minimal example *file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "best_sol_path = \"experiments/3_qubit_Ent_ansatz\"\n",
    "compare_path = \"experiments/3_qubit_U3_ansatz\"\n",
    "print(best_sol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "res_path = os.path.join(best_sol_path,\"results.json\")\n",
    "with open(res_path) as json_file:\n",
    "    results = json.load(json_file)\n",
    "\n",
    "import json\n",
    "comp_res_path = os.path.join(compare_path,\"results.json\")\n",
    "with open(comp_res_path) as json_file:\n",
    "    comp_results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# convert to numpy array\n",
    "results_np = np.array([results[r] for r in results])\n",
    "spearmanr(results_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# convert to numpy array\n",
    "comp_results_np = np.array([comp_results[r] for r in comp_results])\n",
    "spearmanr(comp_results_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from words import ambiguous_verbs\n",
    "\n",
    "# create boxplots\n",
    "results_high = [results[r][1] for r in results if results[r][0]==1]\n",
    "highs = [\"High\" for i in range(len(results_high))]\n",
    "results_low = [1-results[r][1] for r in results if results[r][0]==0]\n",
    "lows = [\"Low\" for i in range(len(results_low))]\n",
    "data = pd.DataFrame({\"Similarity\": results_high+results_low, \"type\": highs+lows})\n",
    "\n",
    "# create boxplots\n",
    "results_high = [results[r][1] for r in results if (results[r][0]==1 and r.split(\" \")[0] not in ambiguous_verbs)]\n",
    "highs = [\"High\" for i in range(len(results_high))]\n",
    "results_low = [1-results[r][1] for r in results if results[r][0]==0 and r.split(\" \")[0] not in ambiguous_verbs]\n",
    "lows = [\"Low\" for i in range(len(results_low))]\n",
    "results_amb = [results[r][1] for r in results if (r.split(\" \")[0] in ambiguous_verbs)]\n",
    "ambs = [\"Amb\" for i in range(len(results_amb))]\n",
    "data = pd.DataFrame({\"Similarity\": results_high+results_low+results_amb, \"Type\": highs+lows+ambs})\n",
    "\n",
    "dims = (10,7)\n",
    "fig, ax = plt.subplots() #figsize=dims\n",
    "#plt.rcParams[\"font.size\"] = \"12\"\n",
    "ax = sns.boxplot(ax=ax, x=\"Type\", y=\"Similarity\", data=data)\n",
    "ax.set(ylim=(0.8, 1.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from words import ambiguous_verbs\n",
    "\n",
    "# create boxplots\n",
    "results_high = [comp_results[r][1] for r in comp_results if (comp_results[r][0]==1 and r.split(\" \")[0] not in ambiguous_verbs)]\n",
    "highs = [\"High\" for i in range(len(results_high))]\n",
    "results_low = [1-comp_results[r][1] for r in comp_results if comp_results[r][0]==0 and r.split(\" \")[0] not in ambiguous_verbs]\n",
    "lows = [\"Low\" for i in range(len(results_low))]\n",
    "results_amb = [comp_results[r][1] for r in comp_results if (r.split(\" \")[0] in ambiguous_verbs)]\n",
    "ambs = [\"Amb\" for i in range(len(results_amb))]\n",
    "data = pd.DataFrame({\"Similarity\": results_high+results_low+results_amb, \"type\": highs+lows+ambs})\n",
    "\n",
    "dims = (10,7)\n",
    "fig, ax = plt.subplots() #figsize=dims\n",
    "#plt.rcParams[\"font.size\"] = \"16\"\n",
    "ax = sns.boxplot(ax=ax, x=\"type\", y=\"Similarity\", data=data)\n",
    "ax.set(ylim=(0.2, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_amb_StEnt = [results[r][1] for r in results if (r.split(\" \")[0] in ambiguous_verbs)]\n",
    "StEnt = [\"StEnt\" for i in range(len(results_amb))]\n",
    "results_amb_U3 = [comp_results[r][1] for r in comp_results if (r.split(\" \")[0] in ambiguous_verbs)]\n",
    "U3 = [\"U3\" for i in range(len(results_amb))]\n",
    "\n",
    "data = pd.DataFrame({\"Similarity\": results_amb_StEnt+results_amb_U3, \"type\": StEnt+U3})\n",
    "\n",
    "dims = (10,7)\n",
    "fig, ax = plt.subplots() #figsize=dims\n",
    "#plt.rcParams[\"font.size\"] = \"16\"\n",
    "ax = sns.boxplot(ax=ax, x=\"type\", y=\"Similarity\", data=data)\n",
    "ax.set(ylim=(0.2, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data[\"type\"]==\"StEnt\"].median())\n",
    "print(data[data[\"type\"]==\"U3\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize vector on Bloch Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Ket, H, Rx, Ry, Rz, CX, sqrt, X, Circuit, SWAP\n",
    "from random import uniform\n",
    "from math import pi\n",
    "\n",
    "\n",
    "# AnsÃ¤tze for 3-qubit states\n",
    "n_amb_params = 9\n",
    "def amb_verb_ansatz(p):\n",
    "    return Ket(0,0,0) >> \\\n",
    "        Rx(p[0]) @ Rx(p[1]) @ Rx(p[2]) >> \\\n",
    "        Ry(p[3]) @ Ry(p[4]) @ Ry(p[5]) >> \\\n",
    "        Rz(p[6]) @ Rz(p[7]) @ Rz(p[8]) >> \\\n",
    "        CX  @ Circuit.id(1) >> \\\n",
    "        Circuit.id(1) @ CX >> \\\n",
    "        Circuit.id(1) @ SWAP >> \\\n",
    "        SWAP @ Circuit.id(1) >> \\\n",
    "        CX @ Circuit.id(1) >> \\\n",
    "        SWAP @ Circuit.id(1) >> \\\n",
    "        Circuit.id(1) @ SWAP @ sqrt(2)\n",
    "        \n",
    "        \n",
    "        # Rz(p[0]) @ Rx(p[1]) @ Circuit.id(1) >> \\\n",
    "        # Rx(p[2]) @ Rz(p[3]) @ Circuit.id(1) >> \\\n",
    "        # CX @ Circuit.id(1) >> \\\n",
    "        # Rx(p[4]) @ Rz(p[5]) @ Rx(p[6]) >> \\\n",
    "        # Rz(p[7]) @ Rx(p[8]) @ Rz(p[9]) >> \\\n",
    "        # Circuit.id(1) @ CX >> \\\n",
    "        # Circuit.id(1) @ Rx(p[10]) @ Rz(p[11]) >> \\\n",
    "        # Circuit.id(1) @ Rz(p[12]) @ Rx(p[13]) >> \\\n",
    "        # Circuit.id(1) @ Circuit.id(1) @ Circuit.id(1) @ sqrt(2)\n",
    "\n",
    "n_unamb_ansatz = 3\n",
    "def unamb_verb_ansatz(p):\n",
    "    return Ket(p[0],p[1],p[2])\n",
    "\n",
    "n_noun_params = 3\n",
    "def noun_ansatz(p):\n",
    "    return Ket(0,0,0) >> \\\n",
    "    Ry(p[0]) @ Ry(p[1]) @ Ry(p[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = os.path.join(best_sol_path,\"params.json\")\n",
    "with open(params_path) as json_file:\n",
    "    params = json.load(json_file)\n",
    "pprint(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend, tk_to_qiskit\n",
    "from qiskit import Aer, execute\n",
    "\n",
    "backend = Aer.get_backend('statevector_simulator')\n",
    "verb = tk_to_qiskit(amb_verb_ansatz(params[\"charge\"][\"p\"]).to_tk())\n",
    "job = execute(verb, backend=backend, shots=1, memory=True)\n",
    "job_result = job.result()\n",
    "print(np.round(np.abs(job_result.get_statevector(verb))**2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(amb_verb_ansatz(params[\"charge\"][\"p\"]).eval().array.flatten()/np.sqrt(2)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(params[\"knock\"][\"p\"])\n",
    "pprint(params[\"carry\"][\"p\"])\n",
    "pprint(params[\"drip\"][\"p\"])\n",
    "pprint(params[\"smooth\"][\"p\"])\n",
    "pprint(params[\"accuse\"][\"p\"])\n",
    "pprint(params[\"intercept\"][\"p\"])\n",
    "pprint(params[\"register\"][\"p\"])\n",
    "pprint(params[\"bill\"][\"p\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_nouns_path = os.path.join(best_sol_path,\"evo_nouns.json\")\n",
    "with open(evo_nouns_path) as json_file:\n",
    "    evo_nouns = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dims = (10,7)\n",
    "fig, ax = plt.subplots(figsize=dims)\n",
    "plt.rcParams[\"font.size\"] = \"14\"\n",
    "plt.plot(range(len(evo_nouns)), evo_nouns, '-b', label='loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"SPSA optimization 3-qubit model - Nouns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_verbs_path = os.path.join(best_sol_path,\"evo_verbs.json\")\n",
    "with open(evo_verbs_path) as json_file:\n",
    "    evo_verbs = json.load(json_file)\n",
    "\n",
    "evo_verbs_compare_path = os.path.join(compare_path,\"evo_verbs.json\")\n",
    "with open(evo_verbs_compare_path) as json_file:\n",
    "    evo_verbs_compare = json.load(json_file)\n",
    "\n",
    "\n",
    "dims = (10,7)\n",
    "fig, ax = plt.subplots(figsize=dims)\n",
    "plt.rcParams[\"font.size\"] = \"14\"\n",
    "plt.plot(range(len(evo_verbs)), evo_verbs, '-b', label='Loss Entangeling layer')\n",
    "plt.plot(range(len(evo_verbs_compare)), evo_verbs_compare, '-r', label='Loss CNOT+U(3) layer')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"SPSA optimization 3-qubit model - Amb. verbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qnlp-ws)",
   "language": "python",
   "name": "qnlp-ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "597cb9212bb6505db551d0fa5a39e44e38662ecd79044286d7f1c9c46fe55c66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
